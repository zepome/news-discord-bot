#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å›½å†…æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ + ä¸–è«–åˆ†æã‚·ã‚¹ãƒ†ãƒ 
Gemini APIã«ã‚ˆã‚‹é«˜ç²¾åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æ
"""

import os
import sys
import re
import requests
import json
import time
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import feedparser
from bs4 import BeautifulSoup
from urllib.parse import quote

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_POLITICS')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

# è¿½è·¡ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
POLITICAL_KEYWORDS = [
    # æ”¿å…š
    'è‡ªæ°‘å…š', 'è‡ªæ°‘', 'å›½æ°‘æ°‘ä¸»å…š', 'å›½æ°‘æ°‘ä¸»', 'å‚æ”¿å…š', 'æ—¥æœ¬ç¶­æ–°ã®ä¼š', 'ç¶­æ–°',
    
    # æ”¿æ²»å®¶
    'é«˜å¸‚æ—©è‹—', 'é«˜å¸‚çµŒæ¸ˆå®‰ä¿ç›¸', 'é«˜å¸‚å¤§è‡£',
    'éº»ç”Ÿå¤ªéƒ', 'éº»ç”Ÿå‰¯ç·è£',
    'ç‰‡å±±ã•ã¤ã', 'å°é‡ç”°ç´€ç¾',
    'èŒ‚æœ¨æ•å……', 'èŒ‚æœ¨å¹¹äº‹é•·',
    'éˆ´æœ¨ä¿Šä¸€', 'éˆ´æœ¨è²¡å‹™å¤§è‡£', 'éˆ´æœ¨è²¡å‹™ç›¸',
    'å°¾å´æ­£ç›´', 'çŸ³åŸä¼¸æ™ƒ', 'çŸ³åŸå®é«˜',
    'å®‰å€æ™‹ä¸‰', 'ä¸‰æ—¥æœˆå¤§é€ ', 'ä¸‰æ—¥æœˆçŸ¥äº‹',
    
    # å½¹è·
    'é¦–ç›¸', 'ç·ç†å¤§è‡£', 'å®˜æˆ¿é•·å®˜', 'è²¡å‹™å¤§è‡£', 'å¤–å‹™å¤§è‡£', 'å¤–ç›¸', 
    'è¾²æ—æ°´ç”£å¤§è‡£', 'è¾²æ°´ç›¸', 'ç’°å¢ƒå¤§è‡£', 'ç’°å¢ƒç›¸', 'é˜²è¡›å¤§è‡£', 'é˜²è¡›ç›¸',
    
    # æ”¿æ²»ãƒ—ãƒ­ã‚»ã‚¹
    'å›½ä¼š', 'è‡¨æ™‚å›½ä¼š', 'é€šå¸¸å›½ä¼š', 'ç‰¹åˆ¥å›½ä¼š',
    'äºˆç®—å§”å“¡ä¼š', 'æœ¬ä¼šè­°', 'å§”å“¡ä¼šè³ªç–‘',
    'å…šé¦–è¨è«–', 'ä»£è¡¨è³ªå•',
    'é–£è­°æ±ºå®š', 'é–£è­°äº†è§£',
    'æ³•æ¡ˆæå‡º', 'æ³•æ¡ˆå¯æ±º', 'æ³•æ¡ˆæˆç«‹',
    'æ–½æ”¿æ–¹é‡æ¼”èª¬', 'æ‰€ä¿¡è¡¨æ˜æ¼”èª¬',
    
    # æ”¿ç­–
    'å¢—ç¨', 'æ¸›ç¨', 'ç¨åˆ¶æ”¹æ­£', 'æ¶ˆè²»ç¨', 'æ‰€å¾—ç¨',
    'é˜²è¡›è²»', 'é˜²è¡›äºˆç®—', 'é˜²è¡›åŠ›å¼·åŒ–',
    'ç¤¾ä¼šä¿éšœ', 'å¹´é‡‘åˆ¶åº¦', 'å¹´é‡‘æ”¹é©',
    'è²¡æº', 'äºˆç®—æ¡ˆ', 'è£œæ­£äºˆç®—',
    'æ†²æ³•æ”¹æ­£', 'å®‰å…¨ä¿éšœ',
    'é–¢ç¨', 'è²¿æ˜“å”å®š',
    'å°‘å­åŒ–å¯¾ç­–', 'å­è‚²ã¦æ”¯æ´',
    'é…å¶è€…æ§é™¤', 'æ‰¶é¤Šæ§é™¤', 'ä½å®…ãƒ­ãƒ¼ãƒ³æ§é™¤',
    
    # æ”¿æ²»ã‚¤ãƒ™ãƒ³ãƒˆ
    'è¡†è­°é™¢é¸æŒ™', 'å‚è­°é™¢é¸æŒ™', 'çµ±ä¸€åœ°æ–¹é¸',
    'ç·è£é¸', 'ä»£è¡¨é¸', 'å…šé¦–é¸',
    'å†…é–£æ”¹é€ ', 'çµ„é–£',
    'è§£æ•£', 'ä¸ä¿¡ä»»æ¡ˆ', 'ä¸ä¿¡ä»»æ±ºè­°',
    'æ”¿æ²»è³‡é‡‘', 'æ”¿æ²»çŒ®é‡‘', 'æ”¿æ²»ã¨ã‚«ãƒ',
    'å†…é–£æ”¯æŒç‡', 'æ”¿å…šæ”¯æŒç‡', 'ä¸–è«–èª¿æŸ»',
    
    # å›½éš›æ”¿æ²»
    'æ—¥ç±³é¦–è„³ä¼šè«‡', 'æ—¥ä¸­é¦–è„³ä¼šè«‡', 'æ—¥éŸ“é¦–è„³ä¼šè«‡',
    'æ—¥ç±³åŒç›Ÿ', 'æ—¥ç±³å®‰å…¨ä¿éšœ',
    'G7ã‚µãƒŸãƒƒãƒˆ', 'G20ã‚µãƒŸãƒƒãƒˆ',
    'å›½é€£ç·ä¼š', 'å›½é€£å®‰ä¿ç†',
    'ASEANé¦–è„³ä¼šè­°',
    'ãƒˆãƒ©ãƒ³ãƒ—å¤§çµ±é ˜', 'ãƒ—ãƒ¼ãƒãƒ³å¤§çµ±é ˜', 'ç¿’è¿‘å¹³å›½å®¶ä¸»å¸­',
]

# é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
EXCLUDE_KEYWORDS = [
    'ãƒ—ãƒ­ãƒ¬ã‚¹', 'æ–°æ—¥æœ¬ãƒ—ãƒ­ãƒ¬ã‚¹', 'WWE', 'NJPW', 'DDT',
    'ãƒ¬ã‚¹ãƒ©ãƒ¼', 'è©¦åˆ', 'ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³', 'ã‚¿ã‚¤ãƒˆãƒ«ãƒãƒƒãƒ', 'ãƒªãƒ³ã‚°',
    'ã‚µãƒƒã‚«ãƒ¼', 'Jãƒªãƒ¼ã‚°', 'ãƒ¯ãƒ¼ãƒ«ãƒ‰ã‚«ãƒƒãƒ—', 'ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°',
    'é‡çƒ', 'ãƒ—ãƒ­é‡çƒ', 'NPB', 'ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒªãƒ¼ã‚°', 'MLB',
    'ãƒã‚¹ã‚±', 'NBA', 'Bãƒªãƒ¼ã‚°',
    'ãƒ†ãƒ‹ã‚¹', 'ã‚´ãƒ«ãƒ•', 'ãƒœã‚¯ã‚·ãƒ³ã‚°', 'æ ¼é—˜æŠ€', 'UFC',
    'èŠ¸èƒ½', 'ã‚¢ã‚¤ãƒ‰ãƒ«', 'ã‚¸ãƒ£ãƒ‹ãƒ¼ã‚º', 'AKB',
    'æ˜ ç”»', 'ãƒ‰ãƒ©ãƒ', 'ã‚¢ãƒ‹ãƒ¡', 'å£°å„ª',
    'ä¿³å„ª', 'å¥³å„ª', 'ã‚¿ãƒ¬ãƒ³ãƒˆ', 'ãŠç¬‘ã„',
    'æ–°è£½å“', 'æ–°å•†å“', 'ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³', 'ã‚»ãƒ¼ãƒ«',
    'ã‚²ãƒ¼ãƒ ', 'ã‚¢ãƒ—ãƒª', 'ã‚¹ãƒãƒ›',
]

# ãƒ¡ãƒ‡ã‚£ã‚¢ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰è¨­å®š
NEWS_FEEDS = {
    'æ—¥çµŒæ–°è': {'url': 'https://www.nikkei.com/rss/', 'language': 'æ—¥æœ¬èª'},
    'ãƒ­ã‚¤ã‚¿ãƒ¼é€šä¿¡': {'url': 'https://jp.reuters.com/rssFeed/topNews', 'language': 'æ—¥æœ¬èª'},
    'æ±æ´‹çµŒæ¸ˆã‚ªãƒ³ãƒ©ã‚¤ãƒ³': {'url': 'https://toyokeizai.net/list/feed/rss', 'language': 'æ—¥æœ¬èª'},
    'PRã‚¿ã‚¤ãƒ ã‚¹': {'url': 'https://prtimes.jp/main/rss/', 'language': 'æ—¥æœ¬èª'},
    'æ™‚äº‹ãƒ‰ãƒƒãƒˆã‚³ãƒ ': {'url': 'https://www.jiji.com/rss/atom.xml', 'language': 'æ—¥æœ¬èª'},
    'Bloomberg': {'url': 'https://feeds.bloomberg.com/markets/news.rss', 'language': 'English'},
    'FXStreet': {'url': 'https://www.fxstreet.com/rss/news', 'language': 'English'},
    'Reuters (è‹±èªç‰ˆ)': {'url': 'https://www.reutersagency.com/feed/?taxonomy=best-topics&post_type=best', 'language': 'English'},
}

class YahooNewsCommentAnalyzer:
    """Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, gemini_api_key: str):
        self.api_key = gemini_api_key
        self.api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
    
    def search_yahoo_news(self, title: str) -> Optional[str]:
        """Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§è¨˜äº‹ã‚’æ¤œç´¢ã—ã¦URLã‚’å–å¾—"""
        try:
            # Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢
            search_query = quote(title[:50])
            search_url = f"https://news.yahoo.co.jp/search?p={search_query}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(search_url, headers=headers, timeout=10)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                # æœ€åˆã®æ¤œç´¢çµæœã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
                article_link = soup.select_one('a.newsFeed_item_link')
                if article_link and article_link.get('href'):
                    yahoo_url = article_link['href']
                    print(f"  ğŸ“° Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ç™ºè¦‹: {yahoo_url}")
                    return yahoo_url
            
            print(f"  âš ï¸ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«è©²å½“è¨˜äº‹ãªã—")
            return None
            
        except Exception as e:
            print(f"  âš ï¸ Yahoo!æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def get_yahoo_comments(self, article_url: str, max_comments: int = 100) -> List[Dict]:
        """Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—"""
        try:
            # Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆAPIã‚’ä½¿ç”¨
            # æ³¨æ„: ã“ã®éƒ¨åˆ†ã¯å®Ÿéš›ã®Yahoo! APIã®ä»•æ§˜ã«åˆã‚ã›ã¦èª¿æ•´ãŒå¿…è¦
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(article_url, headers=headers, timeout=10)
            
            if response.status_code != 200:
                print(f"  âš ï¸ ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—å¤±æ•—: {response.status_code}")
                return []
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ï¼ˆå®Ÿéš›ã®æ§‹é€ ã«åˆã‚ã›ã¦èª¿æ•´ï¼‰
            comments = []
            comment_elements = soup.select('.comment')[:max_comments]
            
            for elem in comment_elements:
                comment_text = elem.get_text(strip=True)
                if comment_text:
                    comments.append({
                        'text': comment_text,
                        'likes': 0  # ã„ã„ã­æ•°ã‚‚å–å¾—å¯èƒ½
                    })
            
            print(f"  ğŸ’¬ ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—: {len(comments)}ä»¶")
            return comments
            
        except Exception as e:
            print(f"  âš ï¸ ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def analyze_sentiment_with_gemini(self, title: str, comments: List[Dict]) -> Dict:
        """Gemini APIã§ã‚³ãƒ¡ãƒ³ãƒˆã®æ„Ÿæƒ…åˆ†æ"""
        if not comments:
            return self._empty_analysis()
        
        try:
            # ã‚³ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
            comments_text = "\n".join([f"- {c['text'][:200]}" for c in comments[:50]])
            
            prompt = f"""ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«å¯¾ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆYahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã€‘
{title}

ã€ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ50ä»¶ï¼‰ã€‘
{comments_text}

ä»¥ä¸‹ã®é …ç›®ã‚’åˆ†æã—ã¦ã€JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

{{
  "sentiment_ratio": {{
    "positive": è³›æˆãƒ»å¥½æ„çš„ãªå‰²åˆï¼ˆ0-100ï¼‰,
    "negative": åå¯¾ãƒ»å¦å®šçš„ãªå‰²åˆï¼ˆ0-100ï¼‰,
    "neutral": ä¸­ç«‹ãƒ»ãã®ä»–ã®å‰²åˆï¼ˆ0-100ï¼‰
  }},
  "temperature_score": è­°è«–ã®ç†±é‡ã‚¹ã‚³ã‚¢ï¼ˆ0-100ã€100ãŒæœ€ã‚‚ç†±ã„ï¼‰,
  "main_opinions": [
    {{"stance": "positive", "opinion": "è³›æˆæ´¾ã®ä¸»ãªæ„è¦‹"}},
    {{"stance": "negative", "opinion": "åå¯¾æ´¾ã®ä¸»ãªæ„è¦‹"}},
    {{"stance": "neutral", "opinion": "ä¸­ç«‹æ´¾ã®ä¸»ãªæ„è¦‹"}}
  ],
  "representative_comments": [
    {{"stance": "positive", "comment": "è³›æˆæ´¾ã®ä»£è¡¨çš„ã‚³ãƒ¡ãƒ³ãƒˆ"}},
    {{"stance": "negative", "comment": "åå¯¾æ´¾ã®ä»£è¡¨çš„ã‚³ãƒ¡ãƒ³ãƒˆ"}},
    {{"stance": "neutral", "comment": "ä¸­ç«‹æ´¾ã®ä»£è¡¨çš„ã‚³ãƒ¡ãƒ³ãƒˆ"}}
  ],
  "summary": "ä¸–è«–ã®å…¨ä½“çš„ãªå‚¾å‘ã‚’1-2æ–‡ã§è¦ç´„"
}}"""

            headers = {'Content-Type': 'application/json'}
            data = {
                "contents": [{
                    "parts": [{"text": prompt}]
                }]
            }
            
            response = requests.post(
                f"{self.api_url}?key={self.api_key}",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                text_response = result['candidates'][0]['content']['parts'][0]['text']
                
                # JSONã‚’æŠ½å‡º
                json_match = re.search(r'\{.*\}', text_response, re.DOTALL)
                if json_match:
                    analysis = json.loads(json_match.group())
                    print(f"  âœ… ä¸–è«–åˆ†æå®Œäº†")
                    return analysis
            
            print(f"  âš ï¸ Geminiåˆ†æã‚¨ãƒ©ãƒ¼: {response.status_code}")
            return self._empty_analysis()
            
        except Exception as e:
            print(f"  âš ï¸ ä¸–è«–åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._empty_analysis()
    
    def _empty_analysis(self) -> Dict:
        """ç©ºã®åˆ†æçµæœ"""
        return {
            "sentiment_ratio": {"positive": 0, "negative": 0, "neutral": 0},
            "temperature_score": 0,
            "main_opinions": [],
            "representative_comments": [],
            "summary": "ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æãƒ‡ãƒ¼ã‚¿ãªã—"
        }

class GeminiPoliticalFilter:
    """Gemini APIã‚’ä½¿ã£ãŸæ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        if not GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        self.api_key = GEMINI_API_KEY
        self.api_url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
        self.keywords = POLITICAL_KEYWORDS
        self.exclude_keywords = EXCLUDE_KEYWORDS
        self.comment_analyzer = YahooNewsCommentAnalyzer(GEMINI_API_KEY)
        
    def fetch_news_from_feed(self, feed_url: str, source_name: str, max_items: int = 10) -> List[Dict]:
        """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
        try:
            feed = feedparser.parse(feed_url)
            articles = []
            
            for entry in feed.entries[:max_items]:
                article = {
                    'source': source_name,
                    'title': entry.get('title', ''),
                    'link': entry.get('link', ''),
                    'summary': entry.get('summary', entry.get('description', '')),
                    'published': entry.get('published', ''),
                }
                articles.append(article)
            
            return articles
        except Exception as e:
            print(f"âš ï¸ {source_name}ã®ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def contains_keywords(self, text: str) -> Tuple[bool, List[str]]:
        """ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯"""
        if not text:
            return False, []
        
        matched_keywords = []
        text_lower = text.lower()
        
        for keyword in self.keywords:
            if keyword.lower() in text_lower:
                matched_keywords.append(keyword)
        
        return len(matched_keywords) > 0, matched_keywords
    
    def contains_exclude_keywords(self, text: str) -> Tuple[bool, List[str]]:
        """é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒã‚§ãƒƒã‚¯"""
        if not text:
            return False, []
        
        matched_exclude = []
        text_lower = text.lower()
        
        for keyword in self.exclude_keywords:
            if keyword.lower() in text_lower:
                matched_exclude.append(keyword)
        
        return len(matched_exclude) > 0, matched_exclude
    
    def check_political_relevance_with_gemini(self, title: str, summary: str) -> Tuple[int, str]:
        """Gemini APIã§æ”¿æ²»é–¢é€£åº¦ã‚’åˆ¤å®š"""
        try:
            prompt = f"""ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã€Œæ—¥æœ¬ã®å›½å†…æ”¿æ²»ã€ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹0-100ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

åˆ¤å®šåŸºæº–:
- 90-100ç‚¹: å›½ä¼šã€å†…é–£ã€æ”¿å…šã€é¸æŒ™ã€æ³•æ¡ˆã€æ”¿ç­–ãªã©æ˜ç¢ºãªæ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹
- 70-89ç‚¹: æ”¿æ²»å®¶ã®æ”¿æ²»çš„ç™ºè¨€ã€æ”¿æ²»ã‚¤ãƒ™ãƒ³ãƒˆã€æ”¿æ²»çš„å½±éŸ¿ã®ã‚ã‚‹çµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹
- 50-69ç‚¹: æ”¿æ²»å®¶ãŒç™»å ´ã™ã‚‹ãŒæ”¿æ²»æ´»å‹•ä»¥å¤–ã®è©±é¡Œ
- 0-49ç‚¹: æ”¿æ²»ã¨ç„¡é–¢ä¿‚

ãƒ‹ãƒ¥ãƒ¼ã‚¹:
ã‚¿ã‚¤ãƒˆãƒ«: {title}
å†…å®¹: {summary[:300]}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{"score": æ•°å€¤, "reason": "ç°¡æ½”ãªç†ç”±"}}"""

            headers = {'Content-Type': 'application/json'}
            data = {"contents": [{"parts": [{"text": prompt}]}]}
            
            response = requests.post(
                f"{self.api_url}?key={self.api_key}",
                headers=headers,
                json=data,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                text_response = result['candidates'][0]['content']['parts'][0]['text']
                
                json_match = re.search(r'\{[^}]+\}', text_response)
                if json_match:
                    json_data = json.loads(json_match.group())
                    score = int(json_data.get('score', 0))
                    reason = json_data.get('reason', '')
                    return score, reason
                    
            return 50, "API ã‚¨ãƒ©ãƒ¼"
                
        except Exception as e:
            print(f"âš ï¸ Geminiåˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            return 50, f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def filter_political_news(self, all_news: Dict[str, List[Dict]]) -> List[Dict]:
        """æ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° + ä¸–è«–åˆ†æ"""
        candidate_news = []
        
        # ã‚¹ãƒ†ãƒƒãƒ—1: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿
        print("\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—1: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
        for source_name, articles in all_news.items():
            for article in articles:
                title = article['title']
                summary = self._clean_html(article['summary'])
                full_text = f"{title} {summary}"
                
                has_keyword, matched = self.contains_keywords(full_text)
                
                if has_keyword:
                    has_exclude, exclude_matched = self.contains_exclude_keywords(full_text)
                    
                    if has_exclude:
                        print(f"âŒ é™¤å¤–: ã€{source_name}ã€‘ {title[:50]}... (é™¤å¤–: {', '.join(exclude_matched[:2])})")
                        continue
                    
                    article['matched_keywords'] = matched
                    candidate_news.append(article)
                    print(f"âœ… å€™è£œ: ã€{source_name}ã€‘ {title[:50]}... (ã‚­ãƒ¼: {', '.join(matched[:3])})")
        
        print(f"\nğŸ“Š ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ: {len(candidate_news)}ä»¶")
        
        # ã‚¹ãƒ†ãƒƒãƒ—2: Gemini AIã§æ”¿æ²»é–¢é€£åº¦åˆ¤å®š
        print("\nğŸ¤– ã‚¹ãƒ†ãƒƒãƒ—2: Gemini AIã«ã‚ˆã‚‹æ”¿æ²»é–¢é€£åº¦åˆ¤å®š")
        filtered_news = []
        
        for article in candidate_news:
            title = article['title']
            summary = self._clean_html(article['summary'])
            
            score, reason = self.check_political_relevance_with_gemini(title, summary)
            article['political_score'] = score
            article['ai_reason'] = reason
            
            if score >= 70:
                # ã‚¹ãƒ†ãƒƒãƒ—3: ä¸–è«–åˆ†æ
                print(f"\nğŸ“° ä¸–è«–åˆ†æé–‹å§‹: {title[:50]}...")
                yahoo_url = self.comment_analyzer.search_yahoo_news(title)
                
                if yahoo_url:
                    comments = self.comment_analyzer.get_yahoo_comments(yahoo_url)
                    sentiment_analysis = self.comment_analyzer.analyze_sentiment_with_gemini(title, comments)
                    article['sentiment_analysis'] = sentiment_analysis
                    article['yahoo_url'] = yahoo_url
                else:
                    article['sentiment_analysis'] = None
                    article['yahoo_url'] = None
                
                filtered_news.append(article)
                print(f"âœ… åˆæ ¼ [{score}ç‚¹]: {title[:50]}")
                time.sleep(2)  # APIåˆ¶é™å¯¾ç­–
            else:
                print(f"âŒ ä¸åˆæ ¼ [{score}ç‚¹]: {title[:50]}")
        
        filtered_news.sort(key=lambda x: x['political_score'], reverse=True)
        return filtered_news
    
    def fetch_all_news(self) -> Dict[str, List[Dict]]:
        """å…¨ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—"""
        all_news = {}
        
        for source_name, config in NEWS_FEEDS.items():
            feed_url = config['url']
            language = config['language']
            print(f"ğŸ“° {source_name}ï¼ˆ{language}ï¼‰ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ä¸­...")
            articles = self.fetch_news_from_feed(feed_url, source_name)
            all_news[source_name] = articles
            print(f"  â†’ {len(articles)}ä»¶å–å¾—")
        
        return all_news
    
    def _clean_html(self, text: str) -> str:
        """HTMLã‚¿ã‚°ã‚’é™¤å»"""
        text = re.sub(r'<[^>]+>', '', text)
        text = text.replace('&nbsp;', ' ').replace('&amp;', '&')
        text = text.replace('&lt;', '<').replace('&gt;', '>')
        text = text.replace('&quot;', '"')
        return text.strip()

class DiscordNotifier:
    """Discordé€šçŸ¥ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, webhook_url: str):
        if not webhook_url:
            raise ValueError("DISCORD_WEBHOOK_POLITICSç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        self.webhook_url = webhook_url
    
    def send_political_news_with_sentiment(self, filtered_news: List[Dict]) -> bool:
        """æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ + ä¸–è«–åˆ†æã‚’é€ä¿¡"""
        if not filtered_news:
            print("ğŸ“­ æ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            self._send_message("ğŸ›ï¸ **å›½å†…æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹é€Ÿå ±** ğŸ›ï¸\n\nğŸ“­ ã“ã®æ™‚é–“ã§æ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
            return True
        
        now = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')
        
        for article in filtered_news[:5]:  # ä¸Šä½5ä»¶
            message = self._format_article_with_sentiment(article, now)
            self._send_message(message)
            time.sleep(1)
        
        return True
    
    def _format_article_with_sentiment(self, article: Dict, timestamp: str) -> str:
        """è¨˜äº‹ + ä¸–è«–åˆ†æã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        source = article['source']
        title = article['title']
        link = article['link']
        score = article.get('political_score', 0)
        keywords = article['matched_keywords'][:3]
        sentiment = article.get('sentiment_analysis')
        
        message = f"ğŸ›ï¸ **å›½å†…æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ + ä¸–è«–åˆ†æ** ğŸ›ï¸\n"
        message += f"â° {timestamp}\n"
        message += "=" * 50 + "\n\n"
        
        message += f"ğŸ“° **ãƒ‹ãƒ¥ãƒ¼ã‚¹**\n"
        message += f"ã€{source}ã€‘{title}\n"
        message += f"ğŸ¯ æ”¿æ²»é–¢é€£åº¦: {score}ç‚¹ | ğŸ”‘ {', '.join(keywords)}\n"
        message += f"ğŸ”— {link}\n\n"
        
        if sentiment and sentiment.get('sentiment_ratio'):
            message += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            message += "ğŸ“Š **ä¸–è«–ã®åå¿œ**ï¼ˆYahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ¡ãƒ³ãƒˆåˆ†æï¼‰\n\n"
            
            ratio = sentiment['sentiment_ratio']
            message += f"ğŸ­ æ„Ÿæƒ…åˆ†æ:\n"
            message += f"â”œâ”€ ğŸ‘ è³›æˆ: {ratio.get('positive', 0)}%\n"
            message += f"â”œâ”€ ğŸ‘ åå¯¾: {ratio.get('negative', 0)}%\n"
            message += f"â””â”€ ğŸ˜ ä¸­ç«‹: {ratio.get('neutral', 0)}%\n\n"
            
            temp = sentiment.get('temperature_score', 0)
            fire = 'ğŸ”¥' * min(5, temp // 20)
            empty = 'âšª' * (5 - len(fire))
            message += f"ğŸŒ¡ï¸ è­°è«–ã®ç†±é‡: {fire}{empty} ({temp}ç‚¹)\n\n"
            
            if sentiment.get('main_opinions'):
                message += "ğŸ’¬ ä¸»ãªè«–ç‚¹:\n"
                for i, opinion in enumerate(sentiment['main_opinions'][:3], 1):
                    message += f"{i}ï¸âƒ£ {opinion.get('opinion', '')}\n"
                message += "\n"
            
            if sentiment.get('representative_comments'):
                message += "ğŸ—£ï¸ ä»£è¡¨çš„ãªã‚³ãƒ¡ãƒ³ãƒˆ:\n"
                for comment in sentiment['representative_comments'][:3]:
                    stance = comment.get('stance', '')
                    text = comment.get('comment', '')
                    emoji = {'positive': 'ğŸ‘', 'negative': 'ğŸ‘', 'neutral': 'ğŸ˜'}.get(stance, 'ğŸ’¬')
                    message += f"{emoji} {text}\n"
                message += "\n"
            
            message += f"ğŸ“ {sentiment.get('summary', '')}\n"
        else:
            message += "\nâš ï¸ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"
        
        return message
    
    def _send_message(self, content: str) -> bool:
        """Discordã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡"""
        try:
            payload = {
                "content": content,
                "username": "å›½å†…æ”¿æ²»ã‚¦ã‚©ãƒƒãƒãƒ£ãƒ¼ Pro ğŸ›ï¸",
                "avatar_url": "https://cdn-icons-png.flaticon.com/512/3649/3649371.png"
            }
            
            response = requests.post(
                self.webhook_url,
                json=payload,
                headers={'Content-Type': 'application/json'}
            )
            
            if response.status_code == 204:
                print("âœ… Discordã¸ã®æŠ•ç¨¿æˆåŠŸ")
                return True
            else:
                print(f"âŒ DiscordæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {response.status_code}")
                return False
                
        except Exception as e:
            print(f"âŒ Discordé€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("ğŸ›ï¸ å›½å†…æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ + ä¸–è«–åˆ†æã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
    print(f"â° å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    try:
        filter_system = GeminiPoliticalFilter()
        all_news = filter_system.fetch_all_news()
        
        total_articles = sum(len(articles) for articles in all_news.values())
        print(f"\nğŸ“Š åˆè¨ˆ {total_articles} ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
        
        if total_articles == 0:
            print("âš ï¸ ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        filtered_news = filter_system.filter_political_news(all_news)
        
        print(f"\nâœ… {len(filtered_news)} ä»¶ã®æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œå‡ºï¼ˆ70ç‚¹ä»¥ä¸Šï¼‰")
        
        notifier = DiscordNotifier(DISCORD_WEBHOOK_URL)
        success = notifier.send_political_news_with_sentiment(filtered_news)
        
        if success:
            print("\nğŸ‰ å‡¦ç†å®Œäº†ï¼")
        else:
            print("\nâš ï¸ DiscordæŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
            
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
