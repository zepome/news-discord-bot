#!/usr/bin/env python3
"""
æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†Botï¼ˆåŸºæœ¬ç‰ˆï¼‰
"""

import os
import sys
import re
import time
from datetime import datetime
import feedparser
import requests
import google.generativeai as genai

# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_POLITICS')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
POLITICAL_SCORE_THRESHOLD = int(os.environ.get('POLITICAL_SCORE_THRESHOLD', '60'))
MAX_NEWS_TO_POST = int(os.environ.get('MAX_NEWS_TO_POST', '3'))


# Gemini APIè¨­å®š
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')

# æ”¿æ²»é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
POLITICAL_KEYWORDS = [
    'è‡ªæ°‘', 'å›½æ°‘æ°‘ä¸»', 'å‚æ”¿', 'ç¶­æ–°', 'ç«‹æ†²', 'å…±ç”£', 'å…¬æ˜', 'ç¤¾æ°‘',
    'é«˜å¸‚', 'éº»ç”Ÿ', 'ç‰‡å±±', 'å°é‡ç”°', 'èŒ‚æœ¨', 'éˆ´æœ¨ä¿Šä¸€', 'å²¸ç”°', 'æ²³é‡', 'çŸ³ç ´',
    'é¦–ç›¸', 'ç·ç†', 'å¤§è‡£', 'å®˜æˆ¿é•·å®˜', 'è²¡å‹™å¤§è‡£', 'å¤–ç›¸', 'é˜²è¡›ç›¸',
    'å¢—ç¨', 'æ¸›ç¨', 'é˜²è¡›è²»', 'ç¤¾ä¼šä¿éšœ', 'è²¡æº', 'æ†²æ³•æ”¹æ­£',
    'å›½ä¼š', 'äºˆç®—å§”å“¡ä¼š', 'å…šé¦–è¨è«–', 'é¸æŒ™', 'å†…é–£æ”¹é€ ', 'æ”¿æ²»è³‡é‡‘',
    'æ—¥ç±³', 'æ—¥ä¸­', 'æ—¥éŸ“', 'ãƒˆãƒ©ãƒ³ãƒ—', 'ãƒ—ãƒ¼ãƒãƒ³', 'ç¿’è¿‘å¹³'
]

# é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
EXCLUDE_KEYWORDS = [
    'ãƒ—ãƒ­ãƒ¬ã‚¹', 'æ–°æ—¥æœ¬ãƒ—ãƒ­ãƒ¬ã‚¹', 'ã‚µãƒƒã‚«ãƒ¼', 'é‡çƒ', 'ãƒã‚¹ã‚±',
    'æ˜ ç”»', 'ãƒ‰ãƒ©ãƒ', 'ã‚¢ã‚¤ãƒ‰ãƒ«', 'éˆ´æœ¨ã¿ã®ã‚‹'
]

# RSSãƒ•ã‚£ãƒ¼ãƒ‰
NEWS_FEEDS = {
    'æ—¥çµŒæ–°èãƒ»é€Ÿå ±': 'https://assets.wor.jp/rss/rdf/nikkei/news.rdf',
    'ãƒ­ã‚¤ã‚¿ãƒ¼æ—¥æœ¬èª': 'https://jp.reuters.com/rssFeed/topNews',
    'Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹': 'https://news.yahoo.co.jp/rss/topics/top-picks.xml'
}

def check_political_relevance(title, description):
    """æ”¿æ²»é–¢é€£åº¦ã‚’åˆ¤å®šï¼ˆGemini APIï¼‰"""
    if not GEMINI_API_KEY:
        return 0
    
    try:
        prompt = f"""
ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒæ—¥æœ¬ã®æ”¿æ²»ã«ã©ã‚Œã ã‘é–¢é€£ã—ã¦ã„ã‚‹ã‹ã€0ã€œ100ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
æ•°å­—ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}
èª¬æ˜: {description}
"""
        response = model.generate_content(prompt)
        score_text = response.text.strip()
        score_match = re.search(r'\d+', score_text)
        if score_match:
            return min(100, max(0, int(score_match.group())))
        return 0
    except Exception as e:
        print(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼: {e}")
        return 0

def create_discord_message(news_item, sentiment_analysis=None):
    """
    DiscordæŠ•ç¨¿ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    """
    from datetime import datetime, timezone, timedelta
    
    title = news_item.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
    link = news_item.get('link', '')
    source = news_item.get('source', 'ä¸æ˜')
    score = news_item.get('score', 0)
    
    # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸæ˜Ÿè©•ä¾¡
    if score >= 90:
        stars = 'â­â­â­â­â­'
    elif score >= 80:
        stars = 'â­â­â­â­'
    elif score >= 70:
        stars = 'â­â­â­'
    elif score >= 60:
        stars = 'â­â­'
    else:
        stars = 'â­'
    
    # ç¾åœ¨æ™‚åˆ»ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    time_str = now.strftime('%H:%M')
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
    content = f"ğŸ›ï¸ **ã€æ”¿æ²»ã€‘{title}**\n"
    content += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    content += f"ğŸ“° **å‡ºå…¸**: {source}\n"
    content += f"ğŸ¯ **é–¢é€£åº¦**: {score}ç‚¹ {stars}\n"
    content += f"â° **å–å¾—æ™‚åˆ»**: {time_str}\n"
    content += f"ğŸ”— {link}\n"
    
    # ä¸–è«–åˆ†æãŒã‚ã‚‹å ´åˆ
    if sentiment_analysis:
        content += "\n" + "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        content += "ğŸ“Š **ä¸–è«–åˆ†æ**\n"
        content += sentiment_analysis.get('formatted_analysis', 'åˆ†æçµæœãªã—')
    
    return {'content': content}
def search_yahoo_news(title):
    """
    Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§ã‚¿ã‚¤ãƒˆãƒ«æ¤œç´¢ã—ã¦URLã‚’å–å¾—
    """
    try:
        import urllib.parse
        search_url = f"https://news.yahoo.co.jp/search?p={urllib.parse.quote(title)}"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(search_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # æ¤œç´¢çµæœã®æœ€åˆã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
        first_result = soup.select_one('a[href*="news.yahoo.co.jp/articles/"]')
        if first_result:
            return first_result['href']
        
        return None
    
    except Exception as e:
        print(f"  âš ï¸ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def get_yahoo_comments(article_url, max_comments=100):
    """
    Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
    """
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(article_url, headers=headers, timeout=10)
        response.raise_for_status()
        
        from bs4 import BeautifulSoup
        soup = BeautifulSoup(response.content, 'html.parser')
        
        comments = []
        
        # Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ã‚³ãƒ¡ãƒ³ãƒˆæ§‹é€ ã«å¯¾å¿œ
        comment_elements = soup.select('.comment')[:max_comments]
        
        for elem in comment_elements:
            text_elem = elem.select_one('.commentText')
            if text_elem:
                comment_text = text_elem.get_text(strip=True)
                if comment_text:
                    comments.append({'text': comment_text})
        
        # ã‚³ãƒ¡ãƒ³ãƒˆãŒå–å¾—ã§ããªã„å ´åˆã®ä»£æ›¿æ–¹æ³•
        if not comments:
            # åˆ¥ã®æ§‹é€ ã‚’è©¦ã™
            alt_comments = soup.select('div[class*="comment"]')[:max_comments]
            for elem in alt_comments:
                text = elem.get_text(strip=True)
                if text and len(text) > 10:
                    comments.append({'text': text})
        
        return comments[:max_comments]
    
    except Exception as e:
        print(f"  âš ï¸ ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def analyze_sentiment(comments):
    """
    Gemini APIã§ã‚³ãƒ¡ãƒ³ãƒˆã®æ„Ÿæƒ…åˆ†æ
    """
    if not comments or not GEMINI_API_KEY:
        return None
    
    try:
        # ä¸Šä½20ä»¶ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æå¯¾è±¡ã«ã™ã‚‹
        top_comments = comments[:20]
        comments_text = "\n".join([f"- {c['text']}" for c in top_comments])
        
        prompt = f"""
ä»¥ä¸‹ã®Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ¡ãƒ³ãƒˆã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€ã‚³ãƒ¡ãƒ³ãƒˆä¸€è¦§ã€‘
{comments_text}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

æ„Ÿæƒ…åˆ†å¸ƒ:
è³›æˆ: XX%
åå¯¾: XX%
ä¸­ç«‹: XX%

è­°è«–ã®ç†±é‡: XXç‚¹

ä¸»è¦è«–ç‚¹:
â€¢ è«–ç‚¹1
â€¢ è«–ç‚¹2
"""
        
        response = model.generate_content(prompt)
        analysis_text = response.text.strip()
        
        # æ„Ÿæƒ…åˆ†å¸ƒã®æŠ½å‡º
        result = {'raw_text': analysis_text}
        
        agree_match = re.search(r'è³›æˆ[ï¼š:]\s*(\d+)%', analysis_text)
        oppose_match = re.search(r'åå¯¾[ï¼š:]\s*(\d+)%', analysis_text)
        neutral_match = re.search(r'ä¸­ç«‹[ï¼š:]\s*(\d+)%', analysis_text)
        
        if agree_match and oppose_match and neutral_match:
            result['sentiment'] = {
                'agree': int(agree_match.group(1)),
                'oppose': int(oppose_match.group(1)),
                'neutral': int(neutral_match.group(1))
            }
        
        # ç†±é‡ã‚¹ã‚³ã‚¢ã®æŠ½å‡º
        heat_match = re.search(r'(\d+)ç‚¹', analysis_text)
        if heat_match:
            result['heat_score'] = int(heat_match.group(1))
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåŒ–ã•ã‚ŒãŸåˆ†æçµæœã‚’ä½œæˆ
        formatted = "\nğŸ’­ **æ„Ÿæƒ…åˆ†å¸ƒ**\n"
        if 'sentiment' in result:
            s = result['sentiment']
            formatted += f"   è³›æˆ: {s['agree']}% | åå¯¾: {s['oppose']}% | ä¸­ç«‹: {s['neutral']}%\n\n"
        
        formatted += "ğŸ”¥ **è­°è«–ã®ç†±é‡**: "
        if 'heat_score' in result:
            formatted += f"{result['heat_score']}ç‚¹\n\n"
        else:
            formatted += "ä¸æ˜\n\n"
        
        # ä¸»è¦è«–ç‚¹ã®æŠ½å‡º
        formatted += "ğŸ“Œ **ä¸»è¦è«–ç‚¹**\n"
        points = re.findall(r'[â€¢ãƒ»]\s*(.+)', analysis_text)
        if points:
            for point in points[:3]:  # æœ€å¤§3ã¤
                formatted += f"   â€¢ {point.strip()}\n"
        else:
            formatted += "   â€¢ åˆ†æãƒ‡ãƒ¼ã‚¿ä¸è¶³\n"
        
        result['formatted_analysis'] = formatted
        
        return result
    
    except Exception as e:
        print(f"  âš ï¸ æ„Ÿæƒ…åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return None
        
def main():
    print("=" * 60)
    print("ğŸ›ï¸ æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†Bot")
    print("=" * 60)
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    if not DISCORD_WEBHOOK_URL:
        print("âŒ DISCORD_WEBHOOK_POLITICS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
    all_entries = []
    for source_name, feed_url in NEWS_FEEDS.items():
        print(f"ğŸ“¡ {source_name} ã‹ã‚‰å–å¾—ä¸­...")
        try:
            feed = feedparser.parse(
                feed_url,
                agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            
            print(f"  ğŸ“Š status={getattr(feed, 'status', 'N/A')}, entries={len(feed.entries)}")
            
            for entry in feed.entries[:20]:
                title = entry.get('title', '')
                description = entry.get('description', '') or entry.get('summary', '')
                
                if title:
                    all_entries.append({
                        'title': title,
                        'description': description,
                        'link': entry.get('link', ''),
                        'source': source_name
                    })
            print(f"  âœ… {len(feed.entries[:20])}ä»¶å–å¾—")
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nåˆè¨ˆ: {len(all_entries)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    keyword_matched = []
    for entry in all_entries:
        combined = f"{entry['title']} {entry['description']}"
        if any(kw in combined for kw in POLITICAL_KEYWORDS):
            if not any(ex in combined for ex in EXCLUDE_KEYWORDS):
                keyword_matched.append(entry)
    
    print(f"âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ: {len(keyword_matched)}ä»¶")
    
    # Geminiåˆ¤å®š
    political_news = []
    for entry in keyword_matched[:10]:  # æœ€å¤§10ä»¶ãƒã‚§ãƒƒã‚¯
        score = check_political_relevance(entry['title'], entry['description'])
        entry['score'] = score
        
        if score >= POLITICAL_SCORE_THRESHOLD:
            political_news.append(entry)
            print(f"  âœ… [{score}ç‚¹] {entry['title']}")
        else:
            print(f"  âŒ [{score}ç‚¹] {entry['title']}")
        
        time.sleep(0.5)
    
    print(f"\nâœ… æœ€çµ‚çµæœ: {len(political_news)}ä»¶")
    
    # DiscordæŠ•ç¨¿
    if not political_news:
        message = {'content': 'ğŸ“­ æ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ'}
        requests.post(DISCORD_WEBHOOK_URL, json=message)
        print("\næ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    posted = 0
    for news in political_news[:MAX_NEWS_TO_POST]:
        print(f"\nå‡¦ç†ä¸­: {news['title']}")
        
        # Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢
        sentiment_analysis = None
        yahoo_url = search_yahoo_news(news['title'])
        
        if yahoo_url:
            print(f"  âœ… Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ç™ºè¦‹: {yahoo_url}")
            comments = get_yahoo_comments(yahoo_url, max_comments=100)
            
            if comments:
                print(f"  âœ… ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—: {len(comments)}ä»¶")
                sentiment_analysis = analyze_sentiment(comments)
                if sentiment_analysis:
                    print(f"  âœ… æ„Ÿæƒ…åˆ†æå®Œäº†")
                time.sleep(1)  # APIåˆ¶é™å¯¾ç­–
            else:
                print(f"  âš ï¸ ã‚³ãƒ¡ãƒ³ãƒˆå–å¾—å¤±æ•—")
        else:
            print(f"  âš ï¸ Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆï¼ˆä¸–è«–åˆ†æä»˜ãï¼‰
        message = create_discord_message(news, sentiment_analysis)
        
        try:
            requests.post(DISCORD_WEBHOOK_URL, json=message, timeout=10)
            posted += 1
            print(f"  âœ… DiscordæŠ•ç¨¿æˆåŠŸ")
            time.sleep(2)
        except Exception as e:
            print(f"  âŒ æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nâœ… å®Œäº†: {posted}ä»¶ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
