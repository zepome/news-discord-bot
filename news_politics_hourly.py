#!/usr/bin/env python3
"""
æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†Botï¼ˆåŸºæœ¬ç‰ˆï¼‰
"""

import os
import sys
import re
import time
from datetime import datetime
import feedparser
import requests
import google.generativeai as genai

# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_POLITICS')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
POLITICAL_SCORE_THRESHOLD = int(os.environ.get('POLITICAL_SCORE_THRESHOLD', '60'))
MAX_NEWS_TO_POST = int(os.environ.get('MAX_NEWS_TO_POST', '3'))


# Gemini APIè¨­å®š
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')

# æ”¿æ²»é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
POLITICAL_KEYWORDS = [
    'è‡ªæ°‘', 'å›½æ°‘æ°‘ä¸»', 'å‚æ”¿', 'ç¶­æ–°', 'ç«‹æ†²', 'å…±ç”£', 'å…¬æ˜', 'ç¤¾æ°‘',
    'é«˜å¸‚', 'éº»ç”Ÿ', 'ç‰‡å±±', 'å°é‡ç”°', 'èŒ‚æœ¨', 'éˆ´æœ¨ä¿Šä¸€', 'å²¸ç”°', 'æ²³é‡', 'çŸ³ç ´',
    'é¦–ç›¸', 'ç·ç†', 'å¤§è‡£', 'å®˜æˆ¿é•·å®˜', 'è²¡å‹™å¤§è‡£', 'å¤–ç›¸', 'é˜²è¡›ç›¸',
    'å¢—ç¨', 'æ¸›ç¨', 'é˜²è¡›è²»', 'ç¤¾ä¼šä¿éšœ', 'è²¡æº', 'æ†²æ³•æ”¹æ­£',
    'å›½ä¼š', 'äºˆç®—å§”å“¡ä¼š', 'å…šé¦–è¨è«–', 'é¸æŒ™', 'å†…é–£æ”¹é€ ', 'æ”¿æ²»è³‡é‡‘',
    'æ—¥ç±³', 'æ—¥ä¸­', 'æ—¥éŸ“', 'ãƒˆãƒ©ãƒ³ãƒ—', 'ãƒ—ãƒ¼ãƒãƒ³', 'ç¿’è¿‘å¹³'
]

# é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
EXCLUDE_KEYWORDS = [
    'ãƒ—ãƒ­ãƒ¬ã‚¹', 'æ–°æ—¥æœ¬ãƒ—ãƒ­ãƒ¬ã‚¹', 'ã‚µãƒƒã‚«ãƒ¼', 'é‡çƒ', 'ãƒã‚¹ã‚±',
    'æ˜ ç”»', 'ãƒ‰ãƒ©ãƒ', 'ã‚¢ã‚¤ãƒ‰ãƒ«', 'éˆ´æœ¨ã¿ã®ã‚‹'
]

# RSSãƒ•ã‚£ãƒ¼ãƒ‰
NEWS_FEEDS = {
    'æ—¥çµŒæ–°èãƒ»é€Ÿå ±': 'https://assets.wor.jp/rss/rdf/nikkei/news.rdf',
    'æ—¥çµŒæ–°èãƒ»æ”¿æ²»çµŒæ¸ˆ': 'https://assets.wor.jp/rss/rdf/nikkei/economy.rdf',
    '47NEWSãƒ»åœ°åŸŸé€Ÿå ±': 'https://assets.wor.jp/rss/rdf/ynlocalnews/news.rdf',
    'Bloombergãƒ»ãƒˆãƒƒãƒ—': 'https://assets.wor.jp/rss/rdf/bloomberg/top.rdf',
    'Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹': 'https://news.yahoo.co.jp/rss/topics/top-picks.xml',
    'æ™‚äº‹ãƒ‰ãƒƒãƒˆã‚³ãƒ ': 'https://www.jiji.com/rss/ranking.rdf',
    'ãƒ­ã‚¤ã‚¿ãƒ¼æ—¥æœ¬èª': 'https://jp.reuters.com/rssFeed/topNews',
    'å…±åŒé€šä¿¡': 'https://www.47news.jp/rss/national.xml',
    'BBC News Japan': 'https://feeds.bbci.co.uk/news/world/asia/rss.xml',
    'CNN Top Stories': 'http://rss.cnn.com/rss/edition_world.rss'
}

def check_political_relevance(title, description):
    """æ”¿æ²»é–¢é€£åº¦ã‚’åˆ¤å®šï¼ˆGemini APIï¼‰"""
    if not GEMINI_API_KEY:
        return 0
    
    try:
        prompt = f"""
ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒæ—¥æœ¬ã®æ”¿æ²»ã«ã©ã‚Œã ã‘é–¢é€£ã—ã¦ã„ã‚‹ã‹ã€0ã€œ100ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
æ•°å­—ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}
èª¬æ˜: {description}
"""
        response = model.generate_content(prompt)
        score_text = response.text.strip()
        score_match = re.search(r'\d+', score_text)
        if score_match:
            return min(100, max(0, int(score_match.group())))
        return 0
    except Exception as e:
        print(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼: {e}")
        return 0

def create_discord_message(news_item, sentiment_analysis=None):
    """
    DiscordæŠ•ç¨¿ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
    """
    from datetime import datetime, timezone, timedelta
    
    title = news_item.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
    link = news_item.get('link', '')
    source = news_item.get('source', 'ä¸æ˜')
    score = news_item.get('score', 0)
    
    # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸæ˜Ÿè©•ä¾¡
    if score >= 90:
        stars = 'â­â­â­â­â­'
    elif score >= 80:
        stars = 'â­â­â­â­'
    elif score >= 70:
        stars = 'â­â­â­'
    elif score >= 60:
        stars = 'â­â­'
    else:
        stars = 'â­'
    
    # ç¾åœ¨æ™‚åˆ»ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    time_str = now.strftime('%H:%M')
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
    content = f"ğŸ›ï¸ **ã€æ”¿æ²»ã€‘{title}**\n"
    content += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    content += f"ğŸ“° **å‡ºå…¸**: {source}\n"
    content += f"ğŸ¯ **é–¢é€£åº¦**: {score}ç‚¹ {stars}\n"
    content += f"â° **å–å¾—æ™‚åˆ»**: {time_str}\n"
    content += f"ğŸ”— {link}\n"
    
    # ä¸–è«–åˆ†æãŒã‚ã‚‹å ´åˆï¼ˆå°†æ¥ã®æ‹¡å¼µç”¨ï¼‰
    if sentiment_analysis:
        content += "\n" + "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        content += "ğŸ“Š **ä¸–è«–åˆ†æ**\n\n"
        content += sentiment_analysis.get('raw_analysis', 'åˆ†æçµæœãªã—')
    
    return {'content': content}

def main():
    print("=" * 60)
    print("ğŸ›ï¸ æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†Bot")
    print("=" * 60)
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    if not DISCORD_WEBHOOK_URL:
        print("âŒ DISCORD_WEBHOOK_POLITICS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
    all_entries = []
    for source_name, feed_url in NEWS_FEEDS.items():
        print(f"ğŸ“¡ {source_name} ã‹ã‚‰å–å¾—ä¸­...")
        try:
            feed = feedparser.parse(
                feed_url,
                agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            
            print(f"  ğŸ“Š status={getattr(feed, 'status', 'N/A')}, entries={len(feed.entries)}")
            
            for entry in feed.entries[:20]:
                title = entry.get('title', '')
                description = entry.get('description', '') or entry.get('summary', '')
                
                if title:
                    all_entries.append({
                        'title': title,
                        'description': description,
                        'link': entry.get('link', ''),
                        'source': source_name
                    })
            print(f"  âœ… {len(feed.entries[:20])}ä»¶å–å¾—")
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nåˆè¨ˆ: {len(all_entries)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    keyword_matched = []
    for entry in all_entries:
        combined = f"{entry['title']} {entry['description']}"
        if any(kw in combined for kw in POLITICAL_KEYWORDS):
            if not any(ex in combined for ex in EXCLUDE_KEYWORDS):
                keyword_matched.append(entry)
    
    print(f"âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ: {len(keyword_matched)}ä»¶")
    
    # Geminiåˆ¤å®š
    political_news = []
    for entry in keyword_matched[:10]:  # æœ€å¤§10ä»¶ãƒã‚§ãƒƒã‚¯
        score = check_political_relevance(entry['title'], entry['description'])
        entry['score'] = score
        
        if score >= POLITICAL_SCORE_THRESHOLD:
            political_news.append(entry)
            print(f"  âœ… [{score}ç‚¹] {entry['title']}")
        else:
            print(f"  âŒ [{score}ç‚¹] {entry['title']}")
        
        time.sleep(0.5)
    
    print(f"\nâœ… æœ€çµ‚çµæœ: {len(political_news)}ä»¶")
    
    # DiscordæŠ•ç¨¿
    if not political_news:
        message = {'content': 'ğŸ“­ æ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ'}
        requests.post(DISCORD_WEBHOOK_URL, json=message)
        print("\næ”¿æ²»é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    posted = 0
    for news in political_news[:MAX_NEWS_TO_POST]:
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆï¼ˆæ”¹è‰¯ç‰ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼‰
        message = create_discord_message(news)
        
        try:
            requests.post(DISCORD_WEBHOOK_URL, json=message, timeout=10)

            posted += 1
            print(f"âœ… DiscordæŠ•ç¨¿: {news['title']}")
            time.sleep(2)
        except Exception as e:
            print(f"âŒ æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nâœ… å®Œäº†: {posted}ä»¶ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
