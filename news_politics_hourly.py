#!/usr/bin/env python3
"""
æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†Botï¼ˆAIã‚³ãƒ¡ãƒ³ãƒˆä»˜ãé‡è¤‡é˜²æ­¢ç‰ˆï¼‰
"""

import os
import sys
import re
import time
import json
import hashlib
from datetime import datetime, timedelta
from pathlib import Path
import feedparser
import requests
import google.generativeai as genai

# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
DISCORD_WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_POLITICS')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
POLITICAL_SCORE_THRESHOLD = int(os.environ.get('POLITICAL_SCORE_THRESHOLD', '70'))
MAX_NEWS_TO_POST = int(os.environ.get('MAX_NEWS_TO_POST', '3'))

# æŠ•ç¨¿å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
HISTORY_FILE = 'posted_news_history.json'
HISTORY_RETENTION_HOURS = 24  # 24æ™‚é–“ä»¥å†…ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯

# Gemini APIè¨­å®š
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash-exp')

# æ”¿æ²»é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
POLITICAL_KEYWORDS = [
    'è‡ªæ°‘', 'å›½æ°‘æ°‘ä¸»', 'å‚æ”¿', 'ç¶­æ–°', 'ç«‹æ†²', 'å…±ç”£', 'å…¬æ˜', 'ç¤¾æ°‘',
    'é«˜å¸‚', 'éº»ç”Ÿ', 'ç‰‡å±±', 'å°é‡ç”°', 'èŒ‚æœ¨', 'éˆ´æœ¨ä¿Šä¸€', 'å²¸ç”°', 'æ²³é‡', 'çŸ³ç ´',
    'é¦–ç›¸', 'ç·ç†', 'å¤§è‡£', 'å®˜æˆ¿é•·å®˜', 'è²¡å‹™å¤§è‡£', 'å¤–ç›¸', 'é˜²è¡›ç›¸',
    'å¢—ç¨', 'æ¸›ç¨', 'é˜²è¡›è²»', 'ç¤¾ä¼šä¿éšœ', 'è²¡æº', 'æ†²æ³•æ”¹æ­£',
    'å›½ä¼š', 'äºˆç®—å§”å“¡ä¼š', 'å…šé¦–è¨è«–', 'é¸æŒ™', 'å†…é–£æ”¹é€ ', 'æ”¿æ²»è³‡é‡‘',
    'æ—¥ç±³', 'æ—¥ä¸­', 'æ—¥éŸ“', 'ãƒˆãƒ©ãƒ³ãƒ—', 'ãƒ—ãƒ¼ãƒãƒ³', 'ç¿’è¿‘å¹³'
]

# é™¤å¤–ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
EXCLUDE_KEYWORDS = [
    'ãƒ—ãƒ­ãƒ¬ã‚¹', 'æ–°æ—¥æœ¬ãƒ—ãƒ­ãƒ¬ã‚¹', 'ã‚µãƒƒã‚«ãƒ¼', 'é‡çƒ', 'ãƒã‚¹ã‚±',
    'æ˜ ç”»', 'ãƒ‰ãƒ©ãƒ', 'ã‚¢ã‚¤ãƒ‰ãƒ«', 'éˆ´æœ¨ã¿ã®ã‚‹'
]

# RSSãƒ•ã‚£ãƒ¼ãƒ‰
NEWS_FEEDS = {
    'æ—¥çµŒæ–°èãƒ»é€Ÿå ±': 'https://assets.wor.jp/rss/rdf/nikkei/news.rdf',
    'ãƒ­ã‚¤ã‚¿ãƒ¼æ—¥æœ¬èª': 'https://jp.reuters.com/rssFeed/topNews',
    'Yahoo!ãƒ‹ãƒ¥ãƒ¼ã‚¹': 'https://news.yahoo.co.jp/rss/topics/top-picks.xml'
}

def generate_news_hash(title, link):
    """
    ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ä¸€æ„ãªè­˜åˆ¥å­ã‚’ç”Ÿæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ« + URLã®ãƒãƒƒã‚·ãƒ¥å€¤ï¼‰
    """
    # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ï¼ˆç©ºç™½ã‚’çµ±ä¸€ã€è¨˜å·ã‚’å‰Šé™¤ï¼‰
    normalized_title = re.sub(r'\s+', ' ', title.strip())
    normalized_title = re.sub(r'[ã€ã€‘ã€ã€ã€Œã€\[\]()ï¼ˆï¼‰]', '', normalized_title)
    
    # URLã¨ã‚¿ã‚¤ãƒˆãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒãƒƒã‚·ãƒ¥åŒ–
    content = f"{normalized_title}|{link}"
    return hashlib.md5(content.encode('utf-8')).hexdigest()

def load_posted_history():
    """
    éå»ã®æŠ•ç¨¿å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
    """
    if not os.path.exists(HISTORY_FILE):
        return {}
    
    try:
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            history = json.load(f)
        
        # å¤ã„å±¥æ­´ã‚’å‰Šé™¤ï¼ˆ24æ™‚é–“ä»¥ä¸Šå‰ï¼‰
        cutoff_time = datetime.now() - timedelta(hours=HISTORY_RETENTION_HOURS)
        cutoff_timestamp = cutoff_time.timestamp()
        
        cleaned_history = {
            hash_id: timestamp 
            for hash_id, timestamp in history.items() 
            if timestamp > cutoff_timestamp
        }
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ãŸå±¥æ­´ã‚’ä¿å­˜
        if len(cleaned_history) < len(history):
            save_posted_history(cleaned_history)
            print(f"ğŸ“ å±¥æ­´ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {len(history)} â†’ {len(cleaned_history)}ä»¶")
        
        return cleaned_history
    
    except Exception as e:
        print(f"âš ï¸ å±¥æ­´èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def save_posted_history(history):
    """
    æŠ•ç¨¿å±¥æ­´ã‚’ä¿å­˜
    """
    try:
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"âš ï¸ å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

def is_duplicate(title, link, posted_history):
    """
    é‡è¤‡ãƒã‚§ãƒƒã‚¯
    """
    news_hash = generate_news_hash(title, link)
    return news_hash in posted_history

def mark_as_posted(title, link, posted_history):
    """
    æŠ•ç¨¿æ¸ˆã¿ã¨ã—ã¦ãƒãƒ¼ã‚¯
    """
    news_hash = generate_news_hash(title, link)
    posted_history[news_hash] = datetime.now().timestamp()

def check_political_relevance(title, description):
    """æ”¿æ²»é–¢é€£åº¦ã‚’åˆ¤å®šï¼ˆGemini APIï¼‰"""
    if not GEMINI_API_KEY:
        return 0
    
    try:
        prompt = f"""
ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒæ—¥æœ¬ã®æ”¿æ²»ã«ã©ã‚Œã ã‘é–¢é€£ã—ã¦ã„ã‚‹ã‹ã€0ã€œ100ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
æ•°å­—ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã‚¿ã‚¤ãƒˆãƒ«: {title}
èª¬æ˜: {description}
"""
        response = model.generate_content(prompt)
        score_text = response.text.strip()
        score_match = re.search(r'\d+', score_text)
        if score_match:
            return min(100, max(0, int(score_match.group())))
        return 0
    except Exception as e:
        print(f"âš ï¸ Gemini APIã‚¨ãƒ©ãƒ¼: {e}")
        return 0

def generate_ai_comment(title, description):
    """
    AIã‚³ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆï¼šè¨˜äº‹ã‹ã‚‰æ—¥æœ¬ãƒ»ä¸–ç•Œã®å‹•å‘ã‚’äºˆæ¸¬
    """
    if not GEMINI_API_KEY:
        return None
    
    try:
        prompt = f"""
ä»¥ä¸‹ã®æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’åˆ†æã—ã€ã“ã®å‡ºæ¥äº‹ãŒä»Šå¾Œã®æ—¥æœ¬ã‚„ä¸–ç•Œã«ã©ã®ã‚ˆã†ãªå½±éŸ¿ã‚’åŠã¼ã™ã‹äºˆæ¸¬ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: {title}
å†…å®¹: {description}

ä»¥ä¸‹ã®å½¢å¼ã§ç°¡æ½”ã«å›ç­”ã—ã¦ãã ã•ã„ï¼ˆå„é …ç›®2-3è¡Œç¨‹åº¦ï¼‰ï¼š

ğŸ‡¯ğŸ‡µ æ—¥æœ¬ã¸ã®å½±éŸ¿:
ï¼ˆæ—¥æœ¬ã®æ”¿æ²»ãƒ»çµŒæ¸ˆãƒ»ç¤¾ä¼šã¸ã®å…·ä½“çš„ãªå½±éŸ¿ã‚’äºˆæ¸¬ï¼‰

ğŸŒ ä¸–ç•Œã¸ã®å½±éŸ¿:
ï¼ˆå›½éš›é–¢ä¿‚ã‚„ä¸–ç•Œæƒ…å‹¢ã¸ã®å½±éŸ¿ã‚’äºˆæ¸¬ï¼‰

ğŸ“Š æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ:
ï¼ˆä»Šå¾Œæ³¨è¦–ã™ã¹ãç‚¹ã‚„å±•é–‹ã®å¯èƒ½æ€§ï¼‰
"""
        
        response = model.generate_content(prompt)
        ai_comment = response.text.strip()
        
        # ã‚³ãƒ¡ãƒ³ãƒˆãŒå–å¾—ã§ããŸã‹ç¢ºèª
        if ai_comment and len(ai_comment) > 20:
            return ai_comment
        else:
            return None
    
    except Exception as e:
        print(f"  âš ï¸ AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None

def create_discord_message(news_item, ai_comment=None):
    """
    DiscordæŠ•ç¨¿ç”¨ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆï¼ˆAIã‚³ãƒ¡ãƒ³ãƒˆä»˜ãï¼‰
    """
    from datetime import datetime, timezone, timedelta
    
    title = news_item.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')
    link = news_item.get('link', '')
    source = news_item.get('source', 'ä¸æ˜')
    score = news_item.get('score', 0)
    
    # ã‚¹ã‚³ã‚¢ã«å¿œã˜ãŸæ˜Ÿè©•ä¾¡
    if score >= 90:
        stars = 'â­â­â­â­â­'
    elif score >= 80:
        stars = 'â­â­â­â­'
    elif score >= 70:
        stars = 'â­â­â­'
    elif score >= 60:
        stars = 'â­â­'
    else:
        stars = 'â­'
    
    # ç¾åœ¨æ™‚åˆ»ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
    jst = timezone(timedelta(hours=9))
    now = datetime.now(jst)
    time_str = now.strftime('%H:%M')
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆ
    content = f"ğŸ›ï¸ **ã€æ”¿æ²»ã€‘{title}**\n"
    content += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    content += f"ğŸ“° **å‡ºå…¸**: {source}\n"
    content += f"ğŸ¯ **é–¢é€£åº¦**: {score}ç‚¹ {stars}\n"
    content += f"â° **å–å¾—æ™‚åˆ»**: {time_str}\n"
    content += f"ğŸ”— {link}\n"
    
    # AIã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆ
    if ai_comment:
        content += "\n" + "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        content += "ğŸ¤– **AIã«ã‚ˆã‚‹å‹•å‘äºˆæ¸¬**\n\n"
        content += ai_comment
        content += "\n"
    
    return {'content': content}

def main():
    print("=" * 60)
    print("ğŸ›ï¸ æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è‡ªå‹•åé›†Botï¼ˆAIã‚³ãƒ¡ãƒ³ãƒˆä»˜ãï¼‰")
    print("=" * 60)
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    if not DISCORD_WEBHOOK_URL:
        print("âŒ DISCORD_WEBHOOK_POLITICS ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    if not GEMINI_API_KEY:
        print("âŒ GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        sys.exit(1)
    
    # æŠ•ç¨¿å±¥æ­´ã®èª­ã¿è¾¼ã¿
    posted_history = load_posted_history()
    print(f"ğŸ“š æŠ•ç¨¿å±¥æ­´: {len(posted_history)}ä»¶\n")
    
    # ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
    all_entries = []
    for source_name, feed_url in NEWS_FEEDS.items():
        print(f"ğŸ“¡ {source_name} ã‹ã‚‰å–å¾—ä¸­...")
        try:
            feed = feedparser.parse(
                feed_url,
                agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            
            print(f"  ğŸ“Š status={getattr(feed, 'status', 'N/A')}, entries={len(feed.entries)}")
            
            for entry in feed.entries[:20]:
                title = entry.get('title', '')
                description = entry.get('description', '') or entry.get('summary', '')
                link = entry.get('link', '')
                
                if title and link:
                    all_entries.append({
                        'title': title,
                        'description': description,
                        'link': link,
                        'source': source_name
                    })
            print(f"  âœ… {len(feed.entries[:20])}ä»¶å–å¾—")
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nåˆè¨ˆ: {len(all_entries)}ä»¶ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—")
    
    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
    new_entries = []
    duplicate_count = 0
    for entry in all_entries:
        if is_duplicate(entry['title'], entry['link'], posted_history):
            duplicate_count += 1
            print(f"  â© ã‚¹ã‚­ãƒƒãƒ—ï¼ˆé‡è¤‡ï¼‰: {entry['title'][:40]}...")
        else:
            new_entries.append(entry)
    
    print(f"ğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯: {duplicate_count}ä»¶ã‚¹ã‚­ãƒƒãƒ—, {len(new_entries)}ä»¶ãŒæ–°è¦")
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    keyword_matched = []
    for entry in new_entries:
        combined = f"{entry['title']} {entry['description']}"
        if any(kw in combined for kw in POLITICAL_KEYWORDS):
            if not any(ex in combined for ex in EXCLUDE_KEYWORDS):
                keyword_matched.append(entry)
    
    print(f"âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒ: {len(keyword_matched)}ä»¶")
    
    # Geminiåˆ¤å®š
    political_news = []
    for entry in keyword_matched[:10]:  # æœ€å¤§10ä»¶ãƒã‚§ãƒƒã‚¯
        score = check_political_relevance(entry['title'], entry['description'])
        entry['score'] = score
        
        if score >= POLITICAL_SCORE_THRESHOLD:
            political_news.append(entry)
            print(f"  âœ… [{score}ç‚¹] {entry['title']}")
        else:
            print(f"  âŒ [{score}ç‚¹] {entry['title']}")
        
        time.sleep(0.5)
    
    print(f"\nâœ… æœ€çµ‚çµæœ: {len(political_news)}ä»¶")
    
    # DiscordæŠ•ç¨¿
    if not political_news:
        print("\nğŸ“­ æŠ•ç¨¿ã™ã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒã‚ã‚Šã¾ã›ã‚“")
        return
    
    posted = 0
    for news in political_news[:MAX_NEWS_TO_POST]:
        print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print(f"å‡¦ç†ä¸­: {news['title']}")
        
        # AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ
        ai_comment = generate_ai_comment(news['title'], news['description'])
        
        if ai_comment:
            print(f"  âœ… AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆå®Œäº†")
        else:
            print(f"  âš ï¸ AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆå¤±æ•—")
        
        time.sleep(1)  # APIåˆ¶é™å¯¾ç­–
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä½œæˆï¼ˆAIã‚³ãƒ¡ãƒ³ãƒˆä»˜ãï¼‰
        message = create_discord_message(news, ai_comment)
        
        try:
            requests.post(DISCORD_WEBHOOK_URL, json=message, timeout=10)
            
            # æŠ•ç¨¿æˆåŠŸã—ãŸã‚‰å±¥æ­´ã«è¿½åŠ 
            mark_as_posted(news['title'], news['link'], posted_history)
            posted += 1
            print(f"  âœ… DiscordæŠ•ç¨¿æˆåŠŸ")
            time.sleep(2)
        except Exception as e:
            print(f"  âŒ æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # å±¥æ­´ã‚’ä¿å­˜
    save_posted_history(posted_history)
    
    print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"âœ… å®Œäº†: {posted}ä»¶ã‚’æŠ•ç¨¿ã—ã¾ã—ãŸ")
    print(f"ğŸ“š ç¾åœ¨ã®å±¥æ­´ä»¶æ•°: {len(posted_history)}ä»¶")

if __name__ == "__main__":
    main()
